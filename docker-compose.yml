version: '3.8'

services:
  # PostgreSQL Database - Optimized for bulk operations
  postgres:
    image: postgres:15-alpine
    container_name: go-fiber-postgres
    ports:
      - "5433:5432"
    environment:
      - POSTGRES_DB=testdb
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
      # Optimize for bulk upload performance
      - POSTGRES_SHARED_BUFFERS=256MB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=1GB
      - POSTGRES_WORK_MEM=16MB
      - POSTGRES_MAINTENANCE_WORK_MEM=128MB
      - POSTGRES_MAX_CONNECTIONS=200
      - POSTGRES_WAL_BUFFERS=16MB
      - POSTGRES_CHECKPOINT_SEGMENTS=32
      - POSTGRES_CHECKPOINT_COMPLETION_TARGET=0.9
    restart: unless-stopped
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/postgres-init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d testdb"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.7'    # Updated to 0.7 CPU
          memory: 768M   # Updated to 768MB RAM
        reservations:
          cpus: '0.3'    # Increased reservation
          memory: 384M   # Increased reservation
    networks:
      - go-fiber-network

  # Redis Cache - Optimized for bulk operations
  redis:
    image: redis:7-alpine
    container_name: go-fiber-redis
    ports:
      - "6379:6379"
    command: [
      "redis-server", 
      "--requirepass", "your_redis_password", 
      "--appendonly", "yes", 
      "--maxmemory", "512mb",           # Increased for bulk operations
      "--maxmemory-policy", "allkeys-lru",
      "--save", "900", "1",             # Optimize persistence
      "--save", "300", "10",
      "--save", "60", "10000",
      "--tcp-keepalive", "300",         # Keep connections alive
      "--timeout", "0",                 # No timeout for bulk operations
      "--tcp-backlog", "511"            # Increase backlog
    ]
    environment:
      - REDIS_PASSWORD=your_redis_password
    restart: unless-stopped
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.3'    # Updated to 0.3 CPU
          memory: 512M   # Updated to 512MB RAM
        reservations:
          cpus: '0.1'
          memory: 256M
    networks:
      - go-fiber-network

  # Main application service - Primary bulk upload handler
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: go-fiber-app
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
      - DATABASE_URL=postgresql://user:password@postgres:5432/testdb?sslmode=disable
      - REDIS_URL=redis:6379
      - REDIS_PASSWORD=your_redis_password
      - JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
      # Optimize for bulk upload - Primary handler
      - DB_MAX_OPEN_CONNS=150
      - DB_MAX_IDLE_CONNS=30
      - DB_CONN_MAX_LIFETIME=1h
      - DB_CONN_MAX_IDLE_TIME=30m
      - REDIS_POOL_SIZE=30
      - REDIS_MIN_IDLE_CONNS=8
      # HTTP timeouts for large bulk uploads
      - READ_TIMEOUT=10m
      - WRITE_TIMEOUT=15m
      - IDLE_TIMEOUT=20m
      - BODY_LIMIT=524288000
    volumes:
      - ./assets:/app/assets:ro
      - ./views:/app/views:ro
      - app-logs:/app/logs
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "--timeout=3", "http://localhost:3000/api/health"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '0.6'    # Updated to 0.6 CPU - Primary bulk upload handler
          memory: 768M   # Updated to 768MB RAM
        reservations:
          cpus: '0.3'    # Increased reservation for primary
          memory: 384M   # Increased reservation for primary
    networks:
      - go-fiber-network

  # Secondary instance for load balancing - Minimal resources
  app-instance-1:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: go-fiber-app-1
    ports:
      - "3001:3000"
    environment:
      - PORT=3000
      - DATABASE_URL=postgresql://user:password@postgres:5432/testdb?sslmode=disable
      - REDIS_URL=redis:6379
      - REDIS_PASSWORD=your_redis_password
      - JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
      # Minimal connection pools for secondary instance
      - DB_MAX_OPEN_CONNS=50
      - DB_MAX_IDLE_CONNS=10
      - DB_CONN_MAX_LIFETIME=1h
      - DB_CONN_MAX_IDLE_TIME=30m
      - REDIS_POOL_SIZE=10
      - REDIS_MIN_IDLE_CONNS=2
      # HTTP timeouts for large bulk uploads
      - READ_TIMEOUT=10m
      - WRITE_TIMEOUT=15m
      - IDLE_TIMEOUT=20m
      - BODY_LIMIT=524288000
    volumes:
      - ./assets:/app/assets:ro
      - ./views:/app/views:ro
      - app-logs-1:/app/logs
    restart: unless-stopped
    profiles:
      - load-balancing
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "--timeout=3", "http://localhost:3000/api/health"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '0.2'    # Updated to 0.2 CPU - Secondary instance
          memory: 256M   # Updated to 256MB RAM
        reservations:
          cpus: '0.1'    # Minimal reservation
          memory: 128M   # Minimal reservation
    networks:
      - go-fiber-network


  # Development service with hot reload
  app-dev:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: go-fiber-app-dev
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
      - DATABASE_URL=postgresql://user:password@postgres:5432/testdb?sslmode=disable
      - REDIS_URL=redis:6379
      - REDIS_PASSWORD=your_redis_password
      - JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
      # HTTP timeouts for large bulk uploads
      - READ_TIMEOUT=10m
      - WRITE_TIMEOUT=15m
      - IDLE_TIMEOUT=20m
      - BODY_LIMIT=524288000
    volumes:
      - .:/app
      - /app/go.mod
      - /app/go.sum
      - ./views:/app/views:ro
      - dev-logs:/app/logs
    restart: unless-stopped
    profiles:
      - development
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "--timeout=3", "http://localhost:3000/api/health"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '0.4'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 256M
    networks:
      - go-fiber-network

networks:
  go-fiber-network:
    driver: bridge

volumes:
  redis-data:
    driver: local
  postgres-data:
    driver: local
  app-logs:
    driver: local
  app-logs-1:
    driver: local
  dev-logs:
    driver: local 